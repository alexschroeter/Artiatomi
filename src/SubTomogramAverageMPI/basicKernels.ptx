//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19805474
// Cuda compilation tools, release 7.5, V7.5.16
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_35
.address_size 64

	// .weak	cudaMalloc
.global .texref texVol;
.global .texref texShift;
.global .texref texVolCplx;

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaDeviceGetAttribute
.weak .func  (.param .b32 func_retval0) cudaDeviceGetAttribute(
	.param .b64 cudaDeviceGetAttribute_param_0,
	.param .b32 cudaDeviceGetAttribute_param_1,
	.param .b32 cudaDeviceGetAttribute_param_2
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaGetDevice
.weak .func  (.param .b32 func_retval0) cudaGetDevice(
	.param .b64 cudaGetDevice_param_0
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessor
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessor(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_3
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_3,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_4
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	rot3d
.visible .entry rot3d(
	.param .u32 rot3d_param_0,
	.param .align 4 .b8 rot3d_param_1[12],
	.param .align 4 .b8 rot3d_param_2[12],
	.param .align 4 .b8 rot3d_param_3[12],
	.param .u64 rot3d_param_4
)
{
	.reg .f32 	%f<33>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<6>;


	ld.param.f32 	%f1, [rot3d_param_1+8];
	ld.param.f32 	%f2, [rot3d_param_1+4];
	ld.param.f32 	%f3, [rot3d_param_1];
	ld.param.f32 	%f4, [rot3d_param_2+8];
	ld.param.f32 	%f5, [rot3d_param_2+4];
	ld.param.f32 	%f6, [rot3d_param_2];
	ld.param.f32 	%f7, [rot3d_param_3+8];
	ld.param.f32 	%f8, [rot3d_param_3+4];
	ld.param.f32 	%f9, [rot3d_param_3];
	ld.param.u64 	%rd1, [rot3d_param_4];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	mov.u32 	%r5, %ctaid.y;
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %ctaid.z;
	mov.u32 	%r10, %ntid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r10, %r9, %r11;
	ld.param.u32 	%r13, [rot3d_param_0];
	shr.u32 	%r14, %r13, 31;
	add.s32 	%r15, %r13, %r14;
	shr.s32 	%r16, %r15, 1;
	cvt.rn.f32.s32	%f10, %r16;
	cvt.rn.f32.u32	%f11, %r4;
	sub.f32 	%f12, %f11, %f10;
	cvt.rn.f32.u32	%f13, %r8;
	sub.f32 	%f14, %f13, %f10;
	cvt.rn.f32.u32	%f15, %r12;
	sub.f32 	%f16, %f15, %f10;
	fma.rn.f32 	%f17, %f3, %f12, %f10;
	fma.rn.f32 	%f18, %f6, %f14, %f17;
	fma.rn.f32 	%f19, %f9, %f16, %f18;
	fma.rn.f32 	%f20, %f2, %f12, %f10;
	fma.rn.f32 	%f21, %f5, %f14, %f20;
	fma.rn.f32 	%f22, %f8, %f16, %f21;
	fma.rn.f32 	%f23, %f1, %f12, %f10;
	fma.rn.f32 	%f24, %f4, %f14, %f23;
	fma.rn.f32 	%f25, %f7, %f16, %f24;
	add.f32 	%f26, %f19, 0f3F000000;
	add.f32 	%f27, %f22, 0f3F000000;
	add.f32 	%f28, %f25, 0f3F000000;
	tex.3d.v4.f32.f32	{%f29, %f30, %f31, %f32}, [texVol, {%f26, %f27, %f28, %f28}];
	mad.lo.s32 	%r17, %r12, %r13, %r8;
	mad.lo.s32 	%r18, %r17, %r13, %r4;
	mul.wide.u32 	%rd4, %r18, 4;
	add.s64 	%rd5, %rd2, %rd4;
	st.global.f32 	[%rd5], %f29;
	ret;
}

	// .globl	rot3dCplx
.visible .entry rot3dCplx(
	.param .u32 rot3dCplx_param_0,
	.param .align 4 .b8 rot3dCplx_param_1[12],
	.param .align 4 .b8 rot3dCplx_param_2[12],
	.param .align 4 .b8 rot3dCplx_param_3[12],
	.param .u64 rot3dCplx_param_4
)
{
	.reg .f32 	%f<33>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<6>;


	ld.param.f32 	%f1, [rot3dCplx_param_1+8];
	ld.param.f32 	%f2, [rot3dCplx_param_1+4];
	ld.param.f32 	%f3, [rot3dCplx_param_1];
	ld.param.f32 	%f4, [rot3dCplx_param_2+8];
	ld.param.f32 	%f5, [rot3dCplx_param_2+4];
	ld.param.f32 	%f6, [rot3dCplx_param_2];
	ld.param.f32 	%f7, [rot3dCplx_param_3+8];
	ld.param.f32 	%f8, [rot3dCplx_param_3+4];
	ld.param.f32 	%f9, [rot3dCplx_param_3];
	ld.param.u64 	%rd1, [rot3dCplx_param_4];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	mov.u32 	%r5, %ctaid.y;
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %ctaid.z;
	mov.u32 	%r10, %ntid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r10, %r9, %r11;
	ld.param.u32 	%r13, [rot3dCplx_param_0];
	shr.u32 	%r14, %r13, 31;
	add.s32 	%r15, %r13, %r14;
	shr.s32 	%r16, %r15, 1;
	cvt.rn.f32.s32	%f10, %r16;
	cvt.rn.f32.u32	%f11, %r4;
	sub.f32 	%f12, %f11, %f10;
	cvt.rn.f32.u32	%f13, %r8;
	sub.f32 	%f14, %f13, %f10;
	cvt.rn.f32.u32	%f15, %r12;
	sub.f32 	%f16, %f15, %f10;
	fma.rn.f32 	%f17, %f3, %f12, %f10;
	fma.rn.f32 	%f18, %f6, %f14, %f17;
	fma.rn.f32 	%f19, %f9, %f16, %f18;
	fma.rn.f32 	%f20, %f2, %f12, %f10;
	fma.rn.f32 	%f21, %f5, %f14, %f20;
	fma.rn.f32 	%f22, %f8, %f16, %f21;
	fma.rn.f32 	%f23, %f1, %f12, %f10;
	fma.rn.f32 	%f24, %f4, %f14, %f23;
	fma.rn.f32 	%f25, %f7, %f16, %f24;
	mad.lo.s32 	%r17, %r12, %r13, %r8;
	mad.lo.s32 	%r18, %r17, %r13, %r4;
	add.f32 	%f26, %f19, 0f3F000000;
	add.f32 	%f27, %f22, 0f3F000000;
	add.f32 	%f28, %f25, 0f3F000000;
	mul.wide.u32 	%rd4, %r18, 8;
	add.s64 	%rd5, %rd2, %rd4;
	tex.3d.v4.f32.f32	{%f29, %f30, %f31, %f32}, [texVolCplx, {%f26, %f27, %f28, %f28}];
	st.global.v2.f32 	[%rd5], {%f29, %f30};
	ret;
}

	// .globl	shift
.visible .entry shift(
	.param .u32 shift_param_0,
	.param .u64 shift_param_1,
	.param .align 4 .b8 shift_param_2[12]
)
{
	.reg .f32 	%f<21>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<6>;


	ld.param.u32 	%r1, [shift_param_0];
	ld.param.u64 	%rd1, [shift_param_1];
	ld.param.f32 	%f1, [shift_param_2+8];
	ld.param.f32 	%f2, [shift_param_2+4];
	ld.param.f32 	%f3, [shift_param_2];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	cvt.rn.f32.s32	%f4, %r5;
	sub.f32 	%f5, %f4, %f3;
	add.f32 	%f6, %f5, 0f3F000000;
	cvt.rn.f32.s32	%f7, %r1;
	div.rn.f32 	%f8, %f6, %f7;
	cvt.rn.f32.s32	%f9, %r9;
	sub.f32 	%f10, %f9, %f2;
	add.f32 	%f11, %f10, 0f3F000000;
	div.rn.f32 	%f12, %f11, %f7;
	cvt.rn.f32.s32	%f13, %r13;
	sub.f32 	%f14, %f13, %f1;
	add.f32 	%f15, %f14, 0f3F000000;
	div.rn.f32 	%f16, %f15, %f7;
	tex.3d.v4.f32.f32	{%f17, %f18, %f19, %f20}, [texShift, {%f8, %f12, %f16, %f16}];
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.s32 	%rd4, %r15, 4;
	add.s64 	%rd5, %rd2, %rd4;
	st.global.f32 	[%rd5], %f17;
	ret;
}

	// .globl	sub
.visible .entry sub(
	.param .u32 sub_param_0,
	.param .u64 sub_param_1,
	.param .u64 sub_param_2,
	.param .f32 sub_param_3
)
{
	.reg .f32 	%f<4>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r1, [sub_param_0];
	ld.param.u64 	%rd1, [sub_param_1];
	ld.param.u64 	%rd2, [sub_param_2];
	ld.param.f32 	%f1, [sub_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f2, [%rd6];
	sub.f32 	%f3, %f2, %f1;
	add.s64 	%rd7, %rd3, %rd5;
	st.global.f32 	[%rd7], %f3;
	ret;
}

	// .globl	add
.visible .entry add(
	.param .u32 add_param_0,
	.param .u64 add_param_1,
	.param .u64 add_param_2
)
{
	.reg .f32 	%f<4>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r1, [add_param_0];
	ld.param.u64 	%rd1, [add_param_1];
	ld.param.u64 	%rd2, [add_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f1, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.f32 	%f2, [%rd7];
	add.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd7], %f3;
	ret;
}

	// .globl	subCplx
.visible .entry subCplx(
	.param .u32 subCplx_param_0,
	.param .u64 subCplx_param_1,
	.param .u64 subCplx_param_2,
	.param .u64 subCplx_param_3,
	.param .f32 subCplx_param_4
)
{
	.reg .f32 	%f<9>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<10>;


	ld.param.u32 	%r1, [subCplx_param_0];
	ld.param.u64 	%rd1, [subCplx_param_1];
	ld.param.u64 	%rd2, [subCplx_param_2];
	ld.param.u64 	%rd3, [subCplx_param_3];
	ld.param.f32 	%f1, [subCplx_param_4];
	cvta.to.global.u64 	%rd4, %rd2;
	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd7, %r15, 8;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.v2.f32 	{%f2, %f3}, [%rd8];
	ld.global.f32 	%f5, [%rd5];
	div.rn.f32 	%f6, %f5, %f1;
	add.s64 	%rd9, %rd4, %rd7;
	sub.f32 	%f7, %f2, %f6;
	st.global.v2.f32 	[%rd9], {%f7, %f3};
	ret;
}

	// .globl	wedgeNorm
.visible .entry wedgeNorm(
	.param .u32 wedgeNorm_param_0,
	.param .u64 wedgeNorm_param_1,
	.param .u64 wedgeNorm_param_2,
	.param .u64 wedgeNorm_param_3,
	.param .u32 wedgeNorm_param_4
)
{
	.reg .pred 	%p<4>;
	.reg .f32 	%f<16>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<12>;


	ld.param.u32 	%r1, [wedgeNorm_param_0];
	ld.param.u64 	%rd4, [wedgeNorm_param_1];
	ld.param.u64 	%rd2, [wedgeNorm_param_2];
	ld.param.u64 	%rd3, [wedgeNorm_param_3];
	ld.param.u32 	%r2, [wedgeNorm_param_4];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r10, %r7, %r8, %r9;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r14, %r11, %r12, %r13;
	mad.lo.s32 	%r15, %r14, %r1, %r10;
	mad.lo.s32 	%r16, %r15, %r1, %r6;
	cvt.u64.u32	%rd1, %r16;
	cvta.to.global.u64 	%rd5, %rd4;
	mul.wide.u32 	%rd6, %r16, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.f32 	%f1, [%rd7];
	setp.eq.s32	%p1, %r2, 0;
	@%p1 bra 	BB12_3;

	mov.f32 	%f15, 0f00000000;
	setp.le.f32	%p2, %f1, 0f00000000;
	@%p2 bra 	BB12_4;

	rcp.rn.f32 	%f15, %f1;
	bra.uni 	BB12_4;

BB12_3:
	cvta.to.global.u64 	%rd8, %rd3;
	ld.global.f32 	%f6, [%rd8];
	mul.f32 	%f7, %f6, 0f3DCCCCCD;
	setp.lt.f32	%p3, %f1, %f7;
	selp.f32	%f8, %f7, %f1, %p3;
	rcp.rn.f32 	%f15, %f8;

BB12_4:
	cvta.to.global.u64 	%rd9, %rd2;
	shl.b64 	%rd10, %rd1, 3;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.v2.f32 	{%f9, %f10}, [%rd11];
	mul.f32 	%f13, %f15, %f10;
	mul.f32 	%f14, %f15, %f9;
	st.global.v2.f32 	[%rd11], {%f14, %f13};
	ret;
}

	// .globl	subCplx2
.visible .entry subCplx2(
	.param .u32 subCplx2_param_0,
	.param .u64 subCplx2_param_1,
	.param .u64 subCplx2_param_2,
	.param .u64 subCplx2_param_3,
	.param .u64 subCplx2_param_4
)
{
	.reg .f32 	%f<9>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<12>;


	ld.param.u32 	%r1, [subCplx2_param_0];
	ld.param.u64 	%rd1, [subCplx2_param_1];
	ld.param.u64 	%rd2, [subCplx2_param_2];
	ld.param.u64 	%rd3, [subCplx2_param_3];
	ld.param.u64 	%rd4, [subCplx2_param_4];
	cvta.to.global.u64 	%rd5, %rd2;
	cvta.to.global.u64 	%rd6, %rd4;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd9, %r15, 8;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.v2.f32 	{%f1, %f2}, [%rd10];
	ld.global.f32 	%f4, [%rd7];
	ld.global.f32 	%f5, [%rd6];
	div.rn.f32 	%f6, %f4, %f5;
	add.s64 	%rd11, %rd5, %rd9;
	sub.f32 	%f7, %f1, %f6;
	st.global.v2.f32 	[%rd11], {%f7, %f2};
	ret;
}

	// .globl	makeReal
.visible .entry makeReal(
	.param .u32 makeReal_param_0,
	.param .u64 makeReal_param_1,
	.param .u64 makeReal_param_2
)
{
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r1, [makeReal_param_0];
	ld.param.u64 	%rd1, [makeReal_param_1];
	ld.param.u64 	%rd2, [makeReal_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f1, [%rd6];
	mul.wide.u32 	%rd7, %r15, 4;
	add.s64 	%rd8, %rd3, %rd7;
	st.global.f32 	[%rd8], %f1;
	ret;
}

	// .globl	makeCplxWithSub
.visible .entry makeCplxWithSub(
	.param .u32 makeCplxWithSub_param_0,
	.param .u64 makeCplxWithSub_param_1,
	.param .u64 makeCplxWithSub_param_2,
	.param .f32 makeCplxWithSub_param_3
)
{
	.reg .f32 	%f<5>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r1, [makeCplxWithSub_param_0];
	ld.param.u64 	%rd1, [makeCplxWithSub_param_1];
	ld.param.u64 	%rd2, [makeCplxWithSub_param_2];
	ld.param.f32 	%f1, [makeCplxWithSub_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f2, [%rd6];
	mul.wide.u32 	%rd7, %r15, 8;
	add.s64 	%rd8, %rd3, %rd7;
	sub.f32 	%f3, %f2, %f1;
	mov.f32 	%f4, 0f00000000;
	st.global.v2.f32 	[%rd8], {%f3, %f4};
	ret;
}

	// .globl	makeCplxWithSquareAndSub
.visible .entry makeCplxWithSquareAndSub(
	.param .u32 makeCplxWithSquareAndSub_param_0,
	.param .u64 makeCplxWithSquareAndSub_param_1,
	.param .u64 makeCplxWithSquareAndSub_param_2,
	.param .f32 makeCplxWithSquareAndSub_param_3
)
{
	.reg .f32 	%f<6>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r1, [makeCplxWithSquareAndSub_param_0];
	ld.param.u64 	%rd1, [makeCplxWithSquareAndSub_param_1];
	ld.param.u64 	%rd2, [makeCplxWithSquareAndSub_param_2];
	ld.param.f32 	%f1, [makeCplxWithSquareAndSub_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f2, [%rd6];
	sub.f32 	%f3, %f2, %f1;
	mul.wide.u32 	%rd7, %r15, 8;
	add.s64 	%rd8, %rd3, %rd7;
	mul.f32 	%f4, %f3, %f3;
	mov.f32 	%f5, 0f00000000;
	st.global.v2.f32 	[%rd8], {%f4, %f5};
	ret;
}

	// .globl	binarize
.visible .entry binarize(
	.param .u32 binarize_param_0,
	.param .u64 binarize_param_1,
	.param .u64 binarize_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r1, [binarize_param_0];
	ld.param.u64 	%rd1, [binarize_param_1];
	ld.param.u64 	%rd2, [binarize_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f1, [%rd6];
	setp.gt.f32	%p1, %f1, 0f3F000000;
	selp.f32	%f2, 0f3F800000, 0f00000000, %p1;
	add.s64 	%rd7, %rd3, %rd5;
	st.global.f32 	[%rd7], %f2;
	ret;
}

	// .globl	mulVol
.visible .entry mulVol(
	.param .u32 mulVol_param_0,
	.param .u64 mulVol_param_1,
	.param .u64 mulVol_param_2
)
{
	.reg .f32 	%f<8>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r1, [mulVol_param_0];
	ld.param.u64 	%rd1, [mulVol_param_1];
	ld.param.u64 	%rd2, [mulVol_param_2];
	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.v2.f32 	{%f1, %f2}, [%rd6];
	mul.wide.u32 	%rd7, %r15, 4;
	add.s64 	%rd8, %rd3, %rd7;
	ld.global.f32 	%f5, [%rd8];
	mul.f32 	%f6, %f2, %f5;
	mul.f32 	%f7, %f1, %f5;
	st.global.v2.f32 	[%rd6], {%f7, %f6};
	ret;
}

	// .globl	mulVolCplx
.visible .entry mulVolCplx(
	.param .u32 mulVolCplx_param_0,
	.param .u64 mulVolCplx_param_1,
	.param .u64 mulVolCplx_param_2
)
{
	.reg .f32 	%f<8>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r1, [mulVolCplx_param_0];
	ld.param.u64 	%rd1, [mulVolCplx_param_1];
	ld.param.u64 	%rd2, [mulVolCplx_param_2];
	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.v2.f32 	{%f1, %f2}, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.f32 	%f5, [%rd7];
	mul.f32 	%f6, %f2, %f5;
	mul.f32 	%f7, %f1, %f5;
	st.global.v2.f32 	[%rd6], {%f7, %f6};
	ret;
}

	// .globl	mul
.visible .entry mul(
	.param .u32 mul_param_0,
	.param .f32 mul_param_1,
	.param .u64 mul_param_2
)
{
	.reg .f32 	%f<8>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r1, [mul_param_0];
	ld.param.f32 	%f1, [mul_param_1];
	ld.param.u64 	%rd1, [mul_param_2];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd3, %r15, 8;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.v2.f32 	{%f2, %f3}, [%rd4];
	mul.f32 	%f6, %f3, %f1;
	mul.f32 	%f7, %f2, %f1;
	st.global.v2.f32 	[%rd4], {%f7, %f6};
	ret;
}

	// .globl	conv
.visible .entry conv(
	.param .u32 conv_param_0,
	.param .u64 conv_param_1,
	.param .u64 conv_param_2
)
{
	.reg .f32 	%f<14>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r1, [conv_param_0];
	ld.param.u64 	%rd1, [conv_param_1];
	ld.param.u64 	%rd2, [conv_param_2];
	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.v2.f32 	{%f1, %f2}, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.v2.f32 	{%f5, %f6}, [%rd7];
	mul.f32 	%f9, %f1, %f5;
	mul.f32 	%f10, %f2, %f6;
	mul.f32 	%f11, %f2, %f5;
	sub.f32 	%f12, %f9, %f10;
	fma.rn.f32 	%f13, %f1, %f6, %f11;
	st.global.v2.f32 	[%rd6], {%f12, %f13};
	ret;
}

	// .globl	correl
.visible .entry correl(
	.param .u32 correl_param_0,
	.param .u64 correl_param_1,
	.param .u64 correl_param_2
)
{
	.reg .f32 	%f<14>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r1, [correl_param_0];
	ld.param.u64 	%rd1, [correl_param_1];
	ld.param.u64 	%rd2, [correl_param_2];
	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	mul.wide.u32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.v2.f32 	{%f1, %f2}, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.v2.f32 	{%f5, %f6}, [%rd7];
	mul.f32 	%f9, %f2, %f6;
	mul.f32 	%f10, %f1, %f6;
	mul.f32 	%f11, %f2, %f5;
	sub.f32 	%f12, %f10, %f11;
	fma.rn.f32 	%f13, %f1, %f5, %f9;
	st.global.v2.f32 	[%rd6], {%f13, %f12};
	ret;
}

	// .globl	bandpass
.visible .entry bandpass(
	.param .u32 bandpass_param_0,
	.param .u64 bandpass_param_1,
	.param .f32 bandpass_param_2,
	.param .f32 bandpass_param_3,
	.param .f32 bandpass_param_4
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<69>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd2, [bandpass_param_1];
	ld.param.f32 	%f9, [bandpass_param_2];
	ld.param.f32 	%f10, [bandpass_param_3];
	ld.param.f32 	%f12, [bandpass_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r1, %r2, %r3;
	mov.u32 	%r5, %ntid.y;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r5, %r6, %r7;
	mov.u32 	%r9, %ntid.z;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r9, %r10, %r11;
	ld.param.u32 	%r13, [bandpass_param_0];
	mad.lo.s32 	%r14, %r12, %r13, %r8;
	mad.lo.s32 	%r15, %r14, %r13, %r4;
	mul.wide.u32 	%rd4, %r15, 8;
	add.s64 	%rd1, %rd3, %rd4;
	ld.global.v2.f32 	{%f13, %f14}, [%rd1];
	shr.u32 	%r16, %r13, 31;
	add.s32 	%r17, %r13, %r16;
	shr.s32 	%r18, %r17, 1;
	cvt.rn.f32.s32	%f15, %r18;
	cvt.rn.f32.u32	%f16, %r4;
	sub.f32 	%f17, %f16, %f15;
	cvt.rn.f32.u32	%f18, %r8;
	sub.f32 	%f19, %f18, %f15;
	cvt.rn.f32.u32	%f20, %r12;
	sub.f32 	%f21, %f20, %f15;
	mul.f32 	%f22, %f19, %f19;
	fma.rn.f32 	%f23, %f17, %f17, %f22;
	fma.rn.f32 	%f24, %f21, %f21, %f23;
	sqrt.rn.f32 	%f3, %f24;
	mul.f32 	%f4, %f12, %f12;
	mov.f32 	%f11, 0f00000000;
	setp.leu.f32	%p1, %f4, 0f00000000;
	mov.f32 	%f68, %f11;
	@%p1 bra 	BB23_2;

	sub.f32 	%f27, %f3, %f10;
	mul.f32 	%f28, %f27, %f27;
	neg.f32 	%f29, %f28;
	div.rn.f32 	%f30, %f29, %f4;
	mul.f32 	%f31, %f30, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f32, %f31;
	mov.f32 	%f33, 0fBF317200;
	fma.rn.f32 	%f34, %f32, %f33, %f30;
	mov.f32 	%f35, 0fB5BFBE8E;
	fma.rn.f32 	%f36, %f32, %f35, %f34;
	mul.f32 	%f26, %f36, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f25,%f26;
	// inline asm
	add.f32 	%f37, %f32, 0f00000000;
	ex2.approx.f32 	%f38, %f37;
	mul.f32 	%f39, %f25, %f38;
	setp.lt.f32	%p2, %f30, 0fC2D20000;
	selp.f32	%f40, 0f00000000, %f39, %p2;
	setp.gt.f32	%p3, %f30, 0f42D20000;
	selp.f32	%f5, 0f7F800000, %f40, %p3;
	mov.f32 	%f68, %f5;

BB23_2:
	mov.f32 	%f6, %f68;
	mov.f32 	%f67, %f11;
	@%p1 bra 	BB23_4;

	sub.f32 	%f44, %f3, %f9;
	mul.f32 	%f45, %f44, %f44;
	neg.f32 	%f46, %f45;
	div.rn.f32 	%f47, %f46, %f4;
	mul.f32 	%f48, %f47, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f49, %f48;
	mov.f32 	%f50, 0fBF317200;
	fma.rn.f32 	%f51, %f49, %f50, %f47;
	mov.f32 	%f52, 0fB5BFBE8E;
	fma.rn.f32 	%f53, %f49, %f52, %f51;
	mul.f32 	%f43, %f53, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f42,%f43;
	// inline asm
	add.f32 	%f54, %f49, 0f00000000;
	ex2.approx.f32 	%f55, %f54;
	mul.f32 	%f56, %f42, %f55;
	setp.lt.f32	%p5, %f47, 0fC2D20000;
	selp.f32	%f57, 0f00000000, %f56, %p5;
	setp.gt.f32	%p6, %f47, 0f42D20000;
	selp.f32	%f67, 0f7F800000, %f57, %p6;

BB23_4:
	mul.f32 	%f58, %f13, %f6;
	setp.gt.f32	%p7, %f3, %f10;
	selp.f32	%f59, %f58, %f13, %p7;
	mul.f32 	%f60, %f14, %f6;
	selp.f32	%f61, %f60, %f14, %p7;
	mul.f32 	%f62, %f59, %f67;
	setp.lt.f32	%p8, %f3, %f9;
	mul.f32 	%f63, %f61, %f67;
	selp.f32	%f64, %f62, %f59, %p8;
	selp.f32	%f65, %f63, %f61, %p8;
	st.global.v2.f32 	[%rd1], {%f64, %f65};
	ret;
}

	// .globl	bandpassFFTShift
.visible .entry bandpassFFTShift(
	.param .u32 bandpassFFTShift_param_0,
	.param .u64 bandpassFFTShift_param_1,
	.param .f32 bandpassFFTShift_param_2,
	.param .f32 bandpassFFTShift_param_3,
	.param .f32 bandpassFFTShift_param_4
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<69>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd2, [bandpassFFTShift_param_1];
	ld.param.f32 	%f9, [bandpassFFTShift_param_2];
	ld.param.f32 	%f10, [bandpassFFTShift_param_3];
	ld.param.f32 	%f12, [bandpassFFTShift_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r1, %r2, %r3;
	mov.u32 	%r5, %ntid.y;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r5, %r6, %r7;
	mov.u32 	%r9, %ntid.z;
	mov.u32 	%r10, %ctaid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r9, %r10, %r11;
	ld.param.u32 	%r13, [bandpassFFTShift_param_0];
	shr.u32 	%r14, %r13, 31;
	add.s32 	%r15, %r13, %r14;
	shr.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r16, %r4;
	rem.s32 	%r18, %r17, %r13;
	add.s32 	%r19, %r16, %r8;
	rem.s32 	%r20, %r19, %r13;
	add.s32 	%r21, %r12, %r16;
	rem.s32 	%r22, %r21, %r13;
	mad.lo.s32 	%r23, %r12, %r13, %r8;
	mad.lo.s32 	%r24, %r23, %r13, %r4;
	mul.wide.s32 	%rd4, %r24, 8;
	add.s64 	%rd1, %rd3, %rd4;
	ld.global.v2.f32 	{%f13, %f14}, [%rd1];
	cvt.rn.f32.s32	%f15, %r16;
	cvt.rn.f32.s32	%f16, %r18;
	sub.f32 	%f17, %f16, %f15;
	cvt.rn.f32.s32	%f18, %r20;
	sub.f32 	%f19, %f18, %f15;
	cvt.rn.f32.s32	%f20, %r22;
	sub.f32 	%f21, %f20, %f15;
	mul.f32 	%f22, %f19, %f19;
	fma.rn.f32 	%f23, %f17, %f17, %f22;
	fma.rn.f32 	%f24, %f21, %f21, %f23;
	sqrt.rn.f32 	%f3, %f24;
	mul.f32 	%f4, %f12, %f12;
	mov.f32 	%f11, 0f00000000;
	setp.leu.f32	%p1, %f4, 0f00000000;
	mov.f32 	%f68, %f11;
	@%p1 bra 	BB24_2;

	sub.f32 	%f27, %f3, %f10;
	mul.f32 	%f28, %f27, %f27;
	neg.f32 	%f29, %f28;
	div.rn.f32 	%f30, %f29, %f4;
	mul.f32 	%f31, %f30, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f32, %f31;
	mov.f32 	%f33, 0fBF317200;
	fma.rn.f32 	%f34, %f32, %f33, %f30;
	mov.f32 	%f35, 0fB5BFBE8E;
	fma.rn.f32 	%f36, %f32, %f35, %f34;
	mul.f32 	%f26, %f36, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f25,%f26;
	// inline asm
	add.f32 	%f37, %f32, 0f00000000;
	ex2.approx.f32 	%f38, %f37;
	mul.f32 	%f39, %f25, %f38;
	setp.lt.f32	%p2, %f30, 0fC2D20000;
	selp.f32	%f40, 0f00000000, %f39, %p2;
	setp.gt.f32	%p3, %f30, 0f42D20000;
	selp.f32	%f5, 0f7F800000, %f40, %p3;
	mov.f32 	%f68, %f5;

BB24_2:
	mov.f32 	%f6, %f68;
	mov.f32 	%f67, %f11;
	@%p1 bra 	BB24_4;

	sub.f32 	%f44, %f3, %f9;
	mul.f32 	%f45, %f44, %f44;
	neg.f32 	%f46, %f45;
	div.rn.f32 	%f47, %f46, %f4;
	mul.f32 	%f48, %f47, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f49, %f48;
	mov.f32 	%f50, 0fBF317200;
	fma.rn.f32 	%f51, %f49, %f50, %f47;
	mov.f32 	%f52, 0fB5BFBE8E;
	fma.rn.f32 	%f53, %f49, %f52, %f51;
	mul.f32 	%f43, %f53, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f42,%f43;
	// inline asm
	add.f32 	%f54, %f49, 0f00000000;
	ex2.approx.f32 	%f55, %f54;
	mul.f32 	%f56, %f42, %f55;
	setp.lt.f32	%p5, %f47, 0fC2D20000;
	selp.f32	%f57, 0f00000000, %f56, %p5;
	setp.gt.f32	%p6, %f47, 0f42D20000;
	selp.f32	%f67, 0f7F800000, %f57, %p6;

BB24_4:
	mul.f32 	%f58, %f13, %f6;
	setp.gt.f32	%p7, %f3, %f10;
	selp.f32	%f59, %f58, %f13, %p7;
	mul.f32 	%f60, %f14, %f6;
	selp.f32	%f61, %f60, %f14, %p7;
	mul.f32 	%f62, %f59, %f67;
	setp.lt.f32	%p8, %f3, %f9;
	mul.f32 	%f63, %f61, %f67;
	selp.f32	%f64, %f62, %f59, %p8;
	selp.f32	%f65, %f63, %f61, %p8;
	st.global.v2.f32 	[%rd1], {%f64, %f65};
	ret;
}

	// .globl	fftshift
.visible .entry fftshift(
	.param .u32 fftshift_param_0,
	.param .u64 fftshift_param_1
)
{
	.reg .f32 	%f<10>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [fftshift_param_1];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	mov.u32 	%r5, %ctaid.y;
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %ctaid.z;
	mov.u32 	%r10, %ntid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r10, %r9, %r11;
	ld.param.u32 	%r13, [fftshift_param_0];
	mad.lo.s32 	%r14, %r12, %r13, %r8;
	mad.lo.s32 	%r15, %r14, %r13, %r4;
	mul.wide.u32 	%rd3, %r15, 8;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.v2.f32 	{%f1, %f2}, [%rd4];
	shr.u32 	%r16, %r13, 31;
	add.s32 	%r17, %r13, %r16;
	shr.s32 	%r18, %r17, 1;
	add.s32 	%r19, %r8, %r4;
	add.s32 	%r20, %r19, %r12;
	mad.lo.s32 	%r21, %r18, -3, %r20;
	and.b32  	%r22, %r21, 1;
	shl.b32 	%r23, %r22, 1;
	cvt.rn.f32.s32	%f5, %r23;
	mov.f32 	%f6, 0f3F800000;
	sub.f32 	%f7, %f6, %f5;
	mul.f32 	%f8, %f2, %f7;
	mul.f32 	%f9, %f1, %f7;
	st.global.v2.f32 	[%rd4], {%f9, %f8};
	ret;
}

	// .globl	fftshift2
.visible .entry fftshift2(
	.param .u32 fftshift2_param_0,
	.param .u64 fftshift2_param_1,
	.param .u64 fftshift2_param_2
)
{
	.reg .f32 	%f<5>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [fftshift2_param_1];
	ld.param.u64 	%rd2, [fftshift2_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	mov.u32 	%r5, %ctaid.y;
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %ctaid.z;
	mov.u32 	%r10, %ntid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r10, %r9, %r11;
	ld.param.u32 	%r13, [fftshift2_param_0];
	shr.u32 	%r14, %r13, 31;
	add.s32 	%r15, %r13, %r14;
	shr.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r16, %r4;
	rem.s32 	%r18, %r17, %r13;
	add.s32 	%r19, %r16, %r8;
	rem.s32 	%r20, %r19, %r13;
	add.s32 	%r21, %r12, %r16;
	rem.s32 	%r22, %r21, %r13;
	mad.lo.s32 	%r23, %r22, %r13, %r20;
	mad.lo.s32 	%r24, %r23, %r13, %r18;
	mul.wide.s32 	%rd5, %r24, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.v2.f32 	{%f1, %f2}, [%rd6];
	mad.lo.s32 	%r25, %r12, %r13, %r8;
	mad.lo.s32 	%r26, %r25, %r13, %r4;
	mul.wide.s32 	%rd7, %r26, 8;
	add.s64 	%rd8, %rd3, %rd7;
	st.global.v2.f32 	[%rd8], {%f1, %f2};
	ret;
}

	// .globl	fftshiftReal
.visible .entry fftshiftReal(
	.param .u32 fftshiftReal_param_0,
	.param .u64 fftshiftReal_param_1,
	.param .u64 fftshiftReal_param_2
)
{
	.reg .f32 	%f<2>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [fftshiftReal_param_1];
	ld.param.u64 	%rd2, [fftshiftReal_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	mov.u32 	%r5, %ctaid.y;
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %ctaid.z;
	mov.u32 	%r10, %ntid.z;
	mov.u32 	%r11, %tid.z;
	mad.lo.s32 	%r12, %r10, %r9, %r11;
	ld.param.u32 	%r13, [fftshiftReal_param_0];
	shr.u32 	%r14, %r13, 31;
	add.s32 	%r15, %r13, %r14;
	shr.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r16, %r4;
	rem.s32 	%r18, %r17, %r13;
	add.s32 	%r19, %r16, %r8;
	rem.s32 	%r20, %r19, %r13;
	add.s32 	%r21, %r12, %r16;
	rem.s32 	%r22, %r21, %r13;
	mad.lo.s32 	%r23, %r22, %r13, %r20;
	mad.lo.s32 	%r24, %r23, %r13, %r18;
	mul.wide.s32 	%rd5, %r24, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f1, [%rd6];
	mad.lo.s32 	%r25, %r12, %r13, %r8;
	mad.lo.s32 	%r26, %r25, %r13, %r4;
	mul.wide.s32 	%rd7, %r26, 4;
	add.s64 	%rd8, %rd3, %rd7;
	st.global.f32 	[%rd8], %f1;
	ret;
}

	// .globl	energynorm
.visible .entry energynorm(
	.param .u32 energynorm_param_0,
	.param .u64 energynorm_param_1,
	.param .u64 energynorm_param_2,
	.param .u64 energynorm_param_3,
	.param .u64 energynorm_param_4,
	.param .u64 energynorm_param_5
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<17>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<15>;


	ld.param.u32 	%r1, [energynorm_param_0];
	ld.param.u64 	%rd2, [energynorm_param_1];
	ld.param.u64 	%rd3, [energynorm_param_2];
	ld.param.u64 	%rd4, [energynorm_param_3];
	ld.param.u64 	%rd5, [energynorm_param_4];
	ld.param.u64 	%rd6, [energynorm_param_5];
	cvta.to.global.u64 	%rd7, %rd4;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r2, %r3, %r4;
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %ctaid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r9, %r6, %r7, %r8;
	mov.u32 	%r10, %ntid.z;
	mov.u32 	%r11, %ctaid.z;
	mov.u32 	%r12, %tid.z;
	mad.lo.s32 	%r13, %r10, %r11, %r12;
	mad.lo.s32 	%r14, %r13, %r1, %r9;
	mad.lo.s32 	%r15, %r14, %r1, %r5;
	cvta.to.global.u64 	%rd8, %rd2;
	mul.wide.u32 	%rd9, %r15, 8;
	add.s64 	%rd10, %rd8, %rd9;
	cvta.to.global.u64 	%rd11, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	ld.global.f32 	%f5, [%rd10];
	mul.f32 	%f6, %f5, %f5;
	cvta.to.global.u64 	%rd13, %rd6;
	ld.global.f32 	%f7, [%rd13];
	div.rn.f32 	%f8, %f6, %f7;
	ld.global.f32 	%f9, [%rd12];
	sub.f32 	%f10, %f9, %f8;
	sqrt.rn.f32 	%f11, %f10;
	cvta.to.global.u64 	%rd14, %rd5;
	ld.global.f32 	%f12, [%rd14];
	sqrt.rn.f32 	%f13, %f12;
	mul.f32 	%f1, %f11, %f13;
	add.s64 	%rd1, %rd7, %rd9;
	mov.f32 	%f4, 0f00000000;
	setp.leu.f32	%p1, %f1, 0f358637BD;
	mov.f32 	%f16, %f4;
	@%p1 bra 	BB28_2;

	ld.global.f32 	%f14, [%rd1];
	div.rn.f32 	%f2, %f14, %f1;
	mov.f32 	%f16, %f2;

BB28_2:
	mov.f32 	%f3, %f16;
	st.global.v2.f32 	[%rd1], {%f3, %f4};
	ret;
}

	// .globl	findmax
.visible .entry findmax(
	.param .u64 findmax_param_0,
	.param .u64 findmax_param_1,
	.param .u64 findmax_param_2,
	.param .f32 findmax_param_3,
	.param .f32 findmax_param_4,
	.param .f32 findmax_param_5
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd3, [findmax_param_0];
	ld.param.u64 	%rd2, [findmax_param_1];
	ld.param.u64 	%rd4, [findmax_param_2];
	ld.param.f32 	%f2, [findmax_param_3];
	ld.param.f32 	%f3, [findmax_param_4];
	ld.param.f32 	%f4, [findmax_param_5];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.global.f32 	%f1, [%rd5];
	cvta.to.global.u64 	%rd1, %rd3;
	ld.global.f32 	%f5, [%rd1];
	setp.leu.f32	%p1, %f1, %f5;
	@%p1 bra 	BB29_2;

	cvta.to.global.u64 	%rd6, %rd2;
	st.global.f32 	[%rd1], %f1;
	ld.global.f32 	%f6, [%rd6];
	st.global.f32 	[%rd1+4], %f6;
	st.global.f32 	[%rd1+8], %f2;
	st.global.f32 	[%rd1+12], %f3;
	st.global.f32 	[%rd1+16], %f4;

BB29_2:
	ret;
}


